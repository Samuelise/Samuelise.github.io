---
title: Tensorflow 2.0 å­¦ä¹ ----å›å½’é—®é¢˜
date: 2020-03-17 19:17:53
tags: tensorflow2.0ç¥ç»ç½‘ç»œ
---

## ç¥ç»ç½‘ç»œå¯¼å…¥

æˆå¹´äººå¤§è„‘ä¸­åŒ…å«äº†çº¦1000äº¿ä¸ªç¥ç»å…ƒï¼Œæ¯ä¸ªç¥ç»å…ƒé€šè¿‡æ ‘çªè·å–è¾“å…¥ä¿¡å·ï¼Œé€šè¿‡è½´çªä¼ é€’è¾“å‡ºä¿¡å·ï¼Œç¥ç»å…ƒä¹‹é—´ç›¸äº’è¿æ¥æ„æˆäº†å·¨å¤§çš„ç¥ç»ç½‘ç»œï¼Œä»è€Œå½¢æˆäº†äººè„‘çš„æ„ŸçŸ¥å’Œæ„è¯†åŸºç¡€ã€‚

![å…¸å‹ç”Ÿç‰©ç¥ç»å…ƒç»“æ„](https://github.com/Samuelise/img-folder/raw/master/img/%E5%85%B8%E5%9E%8B%E7%94%9F%E7%89%A9%E7%A5%9E%E7%BB%8F%E5%85%83%E7%BB%93%E6%9E%84.jpg)

1943å¹´ï¼Œæå‡ºäº†æ¨¡æ‹Ÿç”Ÿç‰©ç¥ç»å…ƒæœºåˆ¶çš„äººå·¥ç¥ç»ç½‘ç»œçš„æ•°å­¦æ¨¡å‹ã€‚æŠ½è±¡æˆä¸‹é¢çš„æ•°å­¦ç»“æ„ï¼š

![ç¥ç»å…ƒæ•°å­¦ç»“æ„](https://github.com/Samuelise/img-folder/raw/master/img/%E7%A5%9E%E7%BB%8F%E5%85%83%E6%95%B0%E5%AD%A6%E7%BB%93%E6%9E%84.jpg)

## çº¿æ€§é—®é¢˜

ç¥ç»å…ƒè¾“å…¥å‘é‡$x=[x_1,x_2,x_3,...,x_n]^T$ï¼Œç»è¿‡å‡½æ•°æ˜ å°„ï¼š$f_\theta:x\rightarrow y$åå¾—åˆ°è¾“å‡ºyï¼Œå…¶ä¸­$\theta$ä¸ºå‡½æ•°è‡ªèº«çš„å‚æ•°ï¼Œåœ¨ä¸€ç§ç®€åŒ–çš„æƒ…å†µä¸‹ï¼Œå³çº¿æ€§å˜æ¢ï¼š$f(x)=w^Tx+bï¼Œw=[w_1,w_2,w_3,...,w_n]^T$ï¼Œå±•å¼€æˆæ ‡é‡å½¢å¼:$f(x)=w_1x_1+w_2x_2+w_3x_3+...+w_nx_n+b$ï¼Œå‚æ•°$\theta$ç¡®å®šäº†ç¥ç»å…ƒçš„çŠ¶æ€ï¼Œå›ºå®šå‚æ•°å³å¯ç¡®å®šæ­¤ç¥ç»å…ƒçš„å¤„ç†é€»è¾‘ã€‚

å¯¹äºNè¾“å…¥çš„ç¥ç»å…ƒæ¨¡å‹ï¼Œåªéœ€é‡‡æ ·N+1ç»„ä¸åŒæ•°æ®ç‚¹å³å¯å®Œç¾æ±‚è§£å‡ºå‚æ•°ã€‚ä½†å®é™…ä¸Šï¼Œå¯¹äºä»»ä½•é‡‡æ ·ç‚¹ï¼Œéƒ½æœ‰å¯èƒ½å­˜åœ¨ä¸€å®šçš„è¯¯å·®ï¼Œæˆ‘ä»¬å‡è®¾è¯¯å·®ğœ–æ»¡è¶³å‡å€¼ä¸ºğœ‡ï¼Œæ–¹å·®$ğœ^2$çš„é«˜æ–¯åˆ†å¸ƒï¼Œæ‰€ä»¥é‡‡é›†åˆ°çš„æ ·æœ¬ä¸ºğ‘¦ = ğ‘¤ğ‘¥ + ğ‘ + ğœ–, ğœ–~ğ’©(ğœ‡, $ğœ^2$)ã€‚

ä¸‹é¢ä»¥w=1.477ï¼Œb=0.089ä¸ºä¾‹

```python
#ç”Ÿæˆæ ·æœ¬æ•°æ®
data=[]  #æ ·æœ¬é›†
for i in range(100):       #100ä¸ªç‚¹
    x=np.random.uniform(-10.,10.)         #éšæœºé‡‡æ ·è¾“å…¥x
    eps=np.random.normal(0.,0.1)          #é«˜æ–¯åˆ†å¸ƒçš„è¯¯å·®
    y=1.477*x+0.089+eps               #åŠ å…¥è¯¯å·®çš„å‡½æ•°
    data.append([x,y])                    #æŠŠæ•°æ®åŠ å…¥æ ·æœ¬é›†ä¸­
data=np.array(data)                     #è½¬æ¢æˆnumpyæ•°ç»„
```



åœ¨å¼•å…¥è¯¯å·®åï¼Œå³ä½¿ç®€å•å¦‚çº¿æ€§æ¨¡å‹ï¼Œå¦‚æœåªé‡‡é›†ä¸¤ä¸ªç‚¹ï¼Œä¹Ÿä¼šå¸¦æ¥å¾ˆå¤§çš„ä¼°è®¡è¯¯å·®ã€‚ä¸ºäº†å‡å°‘ä¼°è®¡è¯¯å·®ï¼Œå¯ä»¥é€šè¿‡é‡‡æ ·å¤šç»„æ•°æ®æ ·æœ¬é›†åˆ$ğ”»$ ={$(ğ‘¥^{(1)}, ğ‘¦^{(1)}), (x^{(2)}, x^{(2)}), â€¦ , (ğ‘¥^{(ğ‘›)}, ğ‘¦^{(ğ‘›)})$}ï¼Œç„¶åæ‰¾å‡ºä¸€æ¡æœ€å¥½çš„ç›´çº¿ï¼Œä½¿å®ƒå°½å¯èƒ½è®©æ‰€æœ‰ç‚¹ï¼Œç¦»è¿™æ¡ç›´çº¿çš„è¯¯å·®ä¹‹å’Œæœ€å°ã€‚å¸¸ç”¨çš„ç”¨é¢„æµ‹å€¼ğ‘¤ğ‘¥(ğ‘–) + ğ‘ä¸çœŸå®å€¼ğ‘¦(ğ‘–)ä¹‹é—´çš„å·®çš„å¹³æ–¹å’Œä½œä¸ºæ€»è¯¯å·®$Lï¼šL=\frac{1}{n}\sum^{n}_{i=1}(wx^{(i)}+b-y^{(i)})^2$ï¼Œç„¶åæœç´¢åˆ°ä¸€ç»„w,bï¼Œä½¿å¾—$L$çš„å€¼æœ€å°ã€‚

```python
#function:è®¡ç®—è¯¯å·®
#param:b,w---å¾…ä¼˜åŒ–å‚æ•°     points---æ ·æœ¬ç‚¹
#returnï¼šå‡æ–¹è¯¯å·®ï¼ˆfloatï¼‰
def mse(b,w,points):
    totalerror=0    #å‡æ–¹å·®è¯¯å·®
    for i in range(0,len(points)):
        x=points[i,0]               #ç¬¬iä¸ªç‚¹çš„xå€¼
        y=points[i,1]               #ç¬¬iä¸ªç‚¹çš„yå€¼
        totalerror+=(y-(w*x+b))**2         #è®¡ç®—å‡æ–¹è¯¯å·®
    return totalerror/float(len(points))
```



## å¯»æ‰¾æ–¹æ³•

### æ¢¯åº¦ä¸‹é™æ³•

åœ¨å•è¾“å…¥çš„æƒ…å†µä¸‹ï¼Œå¯ä»¥é€šè¿‡è®¡ç®—æ¨åˆ°è·å¾—ä¸€ç»„å‡†ç¡®çš„è§£ï¼ˆè§£æè§£ï¼‰ï¼Œä½†åœ¨ä¸€äº›æ›´å¤æ‚çš„æƒ…å†µï¼Œæœ‰å¯èƒ½æ±‚ä¸å‡ºè§£æè§£ï¼Œè€Œéšæœºçš„æœç´¢è¯•é”™åˆå¤ªè€—æ—¶é—´ã€‚

æ¢¯åº¦ä¸‹é™ç®—æ³•(Gradient Descent)æ˜¯ç¥ç»ç½‘ç»œè®­ç»ƒä¸­æœ€å¸¸ç”¨çš„ä¼˜åŒ–ç®—æ³•ï¼Œé…åˆå¼ºå¤§çš„å›¾å½¢å¤„ç†èŠ¯ç‰‡GPU(Graphics Processing Unit)çš„å¹¶è¡ŒåŠ é€Ÿèƒ½åŠ›ï¼Œéå¸¸é€‚åˆä¼˜åŒ–æµ·é‡æ•°æ®çš„ç¥ç»ç½‘ç»œæ¨¡å‹ï¼Œè‡ªç„¶ä¹Ÿé€‚åˆä¼˜åŒ–æˆ‘ä»¬è¿™é‡Œçš„ç¥ç»å…ƒçº¿æ€§æ¨¡å‹ã€‚å‡½æ•°çš„æ¢¯åº¦(Gradient)å®šä¹‰ä¸ºå‡½æ•°å¯¹å„ä¸ªè‡ªå˜é‡çš„åå¯¼æ•°(Partial Derivative)ç»„æˆçš„å‘é‡ã€‚![å‡½æ•°åŠå…¶æ¢¯åº¦å‘é‡](https://github.com/Samuelise/img-folder/raw/master/img/%E5%87%BD%E6%95%B0%E5%8F%8A%E5%85%B6%E6%A2%AF%E5%BA%A6.png)å›¾ä¸­ğ‘¥ğ‘¦å¹³é¢çš„çº¢è‰²ç®­å¤´çš„é•¿åº¦è¡¨ç¤ºæ¢¯åº¦å‘é‡çš„æ¨¡ï¼Œç®­å¤´çš„æ–¹å‘è¡¨ç¤ºæ¢¯åº¦å‘é‡çš„æ–¹å‘ã€‚å¯ä»¥çœ‹åˆ°ï¼Œç®­å¤´çš„æ–¹å‘æ€»æ˜¯æŒ‡å‘å½“å‰ä½ç½®å‡½æ•°å€¼å¢é€Ÿæœ€å¤§çš„æ–¹å‘ï¼Œå‡½æ•°æ›²é¢è¶Šé™¡å³­ï¼Œç®­å¤´çš„é•¿åº¦ä¹Ÿå°±è¶Šé•¿ï¼Œæ¢¯åº¦çš„æ¨¡ä¹Ÿè¶Šå¤§ã€‚

é€šè¿‡ä¸Šé¢çš„ä¾‹å­ï¼Œæˆ‘ä»¬èƒ½ç›´è§‚åœ°æ„Ÿå—åˆ°ï¼Œå‡½æ•°åœ¨å„å¤„çš„æ¢¯åº¦æ–¹å‘âˆ‡ğ‘“æ€»æ˜¯æŒ‡å‘å‡½æ•°å€¼å¢å¤§çš„æ–¹å‘ï¼Œé‚£ä¹ˆæ¢¯åº¦çš„åæ–¹å‘âˆ’âˆ‡ğ‘“åº”æŒ‡å‘å‡½æ•°å€¼å‡å°‘çš„æ–¹å‘ã€‚

åˆ©ç”¨è¿™ä¸€æ€§è´¨ï¼Œæˆ‘ä»¬åªéœ€è¦æŒ‰ç…§$x'=x-ğœ‚âˆ™âˆ‡ğ‘“$ æ›´æ–°è¿­ä»£$x'$ ï¼Œå°±èƒ½è·å¾—è¶Šæ¥è¶Šå°çš„å‡½æ•°å€¼ï¼Œå…¶ä¸­ğœ‚ç”¨æ¥ç¼©æ”¾æ¢¯åº¦å‘é‡ï¼Œä¸€èˆ¬å–è¾ƒå°çš„å€¼ï¼Œå¦‚0.01ï¼Œ0.001ç­‰ï¼Œå¯¹äºä¸€ç»´å‡½æ•°ï¼Œä¸Šè¿°å‘é‡å½¢å¼å¯ä»¥é€€åŒ–æˆæ ‡é‡å½¢å¼ï¼š$ğ‘¥â€² = ğ‘¥ âˆ’ ğœ‚ âˆ™\frac{dğ‘¦}{dğ‘¥}$ ï¼Œè¿­ä»£æ›´æ–°$x'$è‹¥å¹²æ¬¡ï¼Œè¿™æ ·å¾—åˆ°çš„$x'$å¤„çš„å‡½æ•°å€¼$y'$æ˜¯æœ€å°çš„ã€‚

è¿™é‡Œæˆ‘ä»¬è¦æœ€å°åŒ–çš„æ˜¯$L=\frac{1}{n}\sum^{n}_{i=1}(wx^{(i)}+b-y^{(i)})^2$ï¼Œå› ä¸ºæˆ‘ä»¬è¦ä¼˜åŒ–çš„æ˜¯wï¼Œbï¼Œæ‰€ä»¥æœ‰                         $ğ‘¤â€² = ğ‘¤ âˆ’ ğœ‚\frac{ğœ•L}{ğœ•ğ‘¤}$                             $b'=b- ğœ‚\frac{ğœ•L}{ğœ•b}$

### æ¢¯åº¦è®¡ç®—

```python
#function:è®¡ç®—å¯¼æ•°ï¼Œæ›´æ–°w,b
#param:b_current,w_current---å½“å‰b,wçš„å€¼  points---æ ·æœ¬ç‚¹  lr---å­¦ä¹ ç‡
#returnï¼š[new_b,new_w]---æ–°çš„[bï¼Œw] 
def step_gradient(b_current,w_current,points,lr):
    b_gradient=0  #åˆå§‹åŒ–
    w_gradient=0
    m=float(len(points))    #æ€»å…±mä¸ªç‚¹
    for i in range(0,len(points)):
        x=points[i,0]
        y=points[i,1]
        b_gradient+=(2/m)*((w_current*x+b_current)-y)   #Lå¯¹bæ±‚åå¯¼
        w_gradient+=(2/m)*x*((w_current*x+b_current)-y)  #Lå¯¹wæ±‚åå¯¼
    new_b=b_current-(lr*b_gradient)  #æ–°çš„wï¼Œb
    new_w=w_current-(lr*w_gradient)
    return [new_b,new_w]
```

### è¿­ä»£æ›´æ–°

```python
#function:æ¢¯åº¦æ›´æ–°
#param:points---æ ·æœ¬ç‚¹  starting_b---èµ·ç‚¹b  starting_w---èµ·ç‚¹w
#param:lr---å­¦ä¹ ç‡   num_iterations---è¿­ä»£æ¬¡æ•°
#return:[b,w]---è¿­ä»£ç»“æœ[b,w]
def gradient_descent(points,starting_b,starting_w,lr,num_iterations):
    b=starting_b
    w=starting_w
    for step in range(num_iterations):
        b,w=step_gradient(b,w,np.array(points),lr)
        loss=mse(b,w,points)
        if step%50==0:    #æ¯50æ¬¡æ‰“å°ä¸€ä¸‹å½“å‰çš„lossï¼Œw,b
            print(f'iteration:{step},loss:{loss},w:{w},b:{b}')
    return [b,w]
```



### æµ‹è¯•

```python
#ä¸»å‡½æ•°
def main():
    lr=0.01    #å­¦ä¹ ç‡
    initial_b=0        #åˆå§‹åŒ–b
    initial_w=0        #åˆå§‹åŒ–w
    num_iterations=1000           #è®­ç»ƒæ¬¡æ•°
    [b,w]=gradient_descent(data,initial_b,initial_w,lr,num_iterations)
    loss=mse(b,w,data)
    print(f'final loss:{loss},w:{w},b:{b}')  #æ‰“å°æœ€ç»ˆç»“æœ
```

### æµ‹è¯•ç»“æœ

![æµ‹è¯•ç»“æœ](https://raw.githubusercontent.com/Samuelise/img-folder/master/img/æµ‹è¯•ç»“æœ.png))

å¯è§ï¼Œæ­¤æ–¹æ³•åœ¨è§£å†³çº¿æ€§é—®é¢˜å‚æ•°æ±‚è§£æ—¶çš„å¼ºå¤§ä¹‹å¤„ï¼Œåœ¨éçº¿æ€§æˆ–éå¸¸å¤æ‚çš„é—®é¢˜ä¸Šï¼Œå¯èƒ½æ¢¯åº¦ä¸‹é™å¾—åˆ°çš„å¹¶ä¸æ˜¯å…¨å±€æœ€ä¼˜è§£ï¼Œä½†åœ¨å®è·µä¸­ï¼Œæ±‚å¾—çš„æ•°å€¼è§£ï¼Œä»èƒ½å‘æŒ¥å¾ˆå¥½çš„æ•ˆæœï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨ã€‚

## æ€»ç»“

æ¢ä¸€ä¸ªè§’åº¦ï¼Œè¯¥é—®é¢˜å…¶å®æ˜¯ä¸€ä¸ªè¿ç»­é‡çš„é¢„æµ‹é—®é¢˜ï¼Œä»æ•°æ®é›†ä¸­è®­ç»ƒå‡ºæ¨¡å‹ï¼Œä»è€Œé¢„æµ‹æœªå‡ºç°æ ·æœ¬çš„è¾“å‡ºå€¼ã€‚æ›´å‡†ç¡®çš„è¯´ï¼Œæ˜¯ä½¿ç”¨çº¿æ€§æ¨¡å‹å»é€¼è¿‘çœŸå®æ¨¡å‹çš„çº¿æ€§å›å½’é—®é¢˜ã€‚